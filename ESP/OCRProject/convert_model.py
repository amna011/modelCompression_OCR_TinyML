#!/usr/bin/env python3
"""
Convert TensorFlow Lite model to C header file for ESP32 deployment.
Supports multiple model formats and provides detailed conversion information.
"""

import sys
import os
import argparse
from pathlib import Path

def convert_tflite_to_header(tflite_path, output_path=None, model_name="model"):
    """Convert TFLite model to C header file."""
    
    if not os.path.exists(tflite_path):
        print(f"‚ùå Error: Model file not found: {tflite_path}")
        return False
    
    # Determine output path
    if output_path is None:
        output_path = f"{model_name}_data.h"
    
    # Read binary model file
    try:
        with open(tflite_path, 'rb') as f:
            model_data = f.read()
    except Exception as e:
        print(f"‚ùå Error reading model file: {e}")
        return False
    
    # Generate C header file
    try:
        with open(output_path, "w") as f:
            # Header guards and includes
            header_guard = f"{model_name.upper()}_DATA_H"
            f.write(f"#ifndef {header_guard}\n")
            f.write(f"#define {header_guard}\n\n")
            f.write("#include <stdint.h>\n\n")
            
            # Model information
            size_kb = len(model_data) / 1024
            f.write(f"// Generated from: {os.path.basename(tflite_path)}\n")
            f.write(f"// Model size: {len(model_data)} bytes ({size_kb:.2f} KB)\n")
            f.write(f"// Generated by: convert_model.py\n\n")
            
            # Model data array
            f.write(f"const unsigned char {model_name}_data[] = {{\n")
            
            # Write data in chunks of 12 bytes per line for readability
            for i in range(0, len(model_data), 12):
                chunk = model_data[i:i+12]
                hex_values = ', '.join(f'0x{b:02x}' for b in chunk)
                if i + 12 < len(model_data):
                    f.write(f"    {hex_values},\n")
                else:
                    f.write(f"    {hex_values}\n")
            
            f.write("};\n\n")
            
            # Model size constant
            f.write(f"const unsigned int {model_name}_data_len = {len(model_data)};\n\n")
            
            # Close header guard
            f.write(f"#endif // {header_guard}\n")
        
        print(f"‚úÖ Successfully converted {tflite_path} to {output_path}")
        print(f"üìä Model size: {size_kb:.2f} KB ({len(model_data)} bytes)")
        print(f"üîß Include in your code: #include \"{output_path}\"")
        print(f"üìù Use variables: {model_name}_data, {model_name}_data_len")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error writing header file: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(
        description="Convert TensorFlow Lite model to C header for ESP32",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python convert_model.py model.tflite
  python convert_model.py model.tflite -o custom_model.h -n ocr_model
  python convert_model.py ../compressed_models/mobilenetv2_quantized.tflite -n mobilenet
        """
    )
    
    parser.add_argument("model_path", help="Path to TensorFlow Lite model file (.tflite)")
    parser.add_argument("-o", "--output", help="Output header file path (default: model_name_data.h)")
    parser.add_argument("-n", "--name", default="model", help="Model variable name (default: model)")
    
    args = parser.parse_args()
    
    # Validate input file
    if not args.model_path.endswith('.tflite'):
        print("‚ö†Ô∏è  Warning: Input file doesn't have .tflite extension")
    
    # Convert model
    success = convert_tflite_to_header(args.model_path, args.output, args.name)
    
    if success:
        print("\nüöÄ Ready for ESP32 deployment!")
        sys.exit(0)
    else:
        print("\nüí• Conversion failed!")
        sys.exit(1)

if __name__ == "__main__":
    main()